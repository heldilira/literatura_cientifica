```{r}
#| label: import packages

library(readxl)
library(readr)
library(tidyverse)
library(janitor)
library(summarytools)
library(stringr)
library(DT)
library(kableExtra)
library(clipr)
library(httr)
library(rvest)
library(xml2)
library(usethis)
library(gert)
```

```{r}
#| label: Save file to Obsidian

source(file = "qmd_to_md.r")
```

------------------------------------------------------------------------

Obsidian Read and Export

Read Scopus and Scimago databases

```{r}
#| label: reading Scopus database

scopus_2023 <- read_excel("data/scopus_2023.xlsx", 
    sheet = "Scopus Sources Oct. 2023") |> 
  clean_names()
```

```{r}
#| label: reading Scimago database

scimago_2023 <- read_delim("data/scimagojr_2023.csv", 
    delim = ";", escape_double = FALSE, col_types = cols(SJR = col_number()), 
    trim_ws = TRUE) |> 
  clean_names()
```

```{r}
#| label: read qxmd database

# qxmd_2024 <- read_csv("data/qxmd.csv", col_names = FALSE) |>
#   clean_names() |> 
#   mutate(qxmd = TRUE)

# Read the entire file
qxmd_2024 <- read_file("data/qxmd.txt")

# Extract journal names using a regex pattern
qxmd_2024 <- str_match_all(qxmd_2024, '<div class="sb0" id="[^"]*" style="">(.*?)</div>') |>
  map(~ if (nrow(.x) > 0) .x[, 2] else character(0)) |>
  unlist()

# Create a dataframe from the vector of journal names
qxmd_2024 <- tibble(journal_Name = qxmd_2024)
```

```{r}
#| label: selecting variables from scopus and scimago

# Scopus
scopus_mylist <- scopus_2023 |> 
  select(sourcerecord_id, source_title, e_issn, print_issn, active_or_inactive, publishers_name) |>
  filter(sourcerecord_id %in% id_table$source_id)

# Scimago
scimago_mylist <- scimago_2023 |> 
  select(sourceid, title, sjr, sjr_best_quartile, h_index, categories, areas)
```

```{r}
#| label: join scopus and scimago

my_list <- scopus_mylist |> 
  dplyr::left_join(scimago_mylist, join_by(sourcerecord_id == sourceid)) |> 
   left_join(qxmd_2024, join_by(source_title == x1)) |> 
  mutate(scimago_link = str_glue("https://www.scimagojr.com/journalsearch.php?q={sourcerecord_id}&tip=sid&clean=0")) |> 
 mutate(homepage_link = map_chr(scimago_link, extract_homepage_link)) |> 
  mutate(scimago_link2 = str_glue("<a href=\"{homepage_link}\"link</a>"))

#<a href="http://rstudio.com">RStudio</a>

scopus_only <- my_list |> 
  filter(is.na(qxmd))
```

```{r}
# Create the search string

search_scopus <- scopus_only |> 
  mutate(query = str_glue("(SOURCE-ID ({sourcerecord_id}))")) |> 
# Uses pull to extract this new column as a vector.
    pull(query) |> 
# Uses str_c with the collapse argument to concatenate all elements of the vector into a single string, separated by " OR "
  str_c(collapse = " OR ")

write_clip(content = search_scopus)
```

Filtering the hole database to only my favorite journals

```{r}
#| label: Importing the .md file from obsidian
# Path to the Markdown file
obsidian_file <- "/Users/helderlira/Downloads/Obsidian/heldilira/02_projetos_atuais/literatura_cientifica/literatura_cientifica.md"

# Reading the file
markdown <- readLines(obsidian_file)

#Getting the Source-id of every journal
id_table <- str_extract(markdown, "\\(\\s*\\d+\\s*\\)") |> 
  tibble() |> 
  drop_na() |> 
  rename(source_id = "str_extract(markdown, \"\\\\(\\\\s*\\\\d+\\\\s*\\\\)\")") |> 
   mutate(source_id = as.numeric(str_replace_all(source_id, "[()\\s]", "")))

scopus_mylist |>
  left_join(qxmd_2024, join_by(source_title == x1)) |>
  View()
```

Table Creation

```{r}
#| label: create a DT interactive table

# This table only works in browsers as of now (2024-05-08)

datatable(my_list, extensions = 'Buttons', options = list(
  dom = 'Bfrtip', 
  escape = FALSE,
  buttons = c('copy', 'csv', 'excel', 'pdf', 'print'))) |>
  saveWidget("table.html")
```

```{r}
#| label: create a static HTML table
table_static <- kable(my_list, format = "html") 

# Write it to a .html file
write(table_static, "table_static.html")

# Write it to a .md obsdidian compatible file
write(table_static, "table_static.md")
```

```{r}
# datatable(my_list, escape = FALSE)

my_list |> 
  select(scimago_link2, scimago_link) |> 
  datatable(escape = FALSE)
```

```{r}
# Example dataframe
df <- tibble(
  journal = c("Annual Review of Psychology"),
  link = c("https://www.scimagojr.com/journalsearch.php?q=12010&tip=sid&clean=0")
)

# Define a function to fetch and parse the link
extract_homepage_link <- function(url) {
  # Get the webpage content
  page <- httr::GET(url)
  
  # Check if the request was successful
  if (httr::status_code(page) == 200) {
    # Parse the HTML content
    html_content <- read_html(httr::content(page, "text"))
    
    # Extract the specific link using a more targeted CSS selector
    # Adjust the CSS selector to specifically find elements by ID 'question_journal'
    specific_link <- html_content %>%
      html_nodes("#question_journal") %>%  # ID selector
      html_attr("href") %>% # Get the 'href' attribute
      .[1]
    
    # Check if the link is extracted, if not return NA
    if (length(specific_link) > 0) {
      return(specific_link)
    } else {
      return(NA)
    }
  } else {
    return(NA)  # Return NA if the page fails to load
  }
}

# Apply the function to create a new column with the extracted links
df <- df %>%
  mutate(homepage_link = map_chr(link, extract_homepage_link))

# View the updated dataframe
print(df)

```
